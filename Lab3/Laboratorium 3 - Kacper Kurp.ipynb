{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importy\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobranie danych\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "\n",
    "# Porzucenie linii z pustymi etykietami oraz odpowiadajacych im wartosci\n",
    "feature_matrix = heart_disease.data.features.dropna()\n",
    "labels = heart_disease.data.targets.loc[feature_matrix.index]\n",
    "\n",
    "# Przetworzenie zbioru wartości przewidywanych do wartości binarnych\n",
    "y_binary = labels.copy()\n",
    "y_binary['num'] = y_binary['num'].apply(lambda x: 1 if x != 0 else 0)                      \n",
    "\n",
    "# Utworznnie zbioru dummy etykiet\n",
    "x_dummy = pd.get_dummies(feature_matrix, columns=['cp', 'restecg', 'slope','ca','thal'])         \n",
    "\n",
    "# Podział danych na zbiór uczący i testowy\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_dummy, y_binary, test_size=0.2, random_state=268555)\n",
    "\n",
    "# Normalizacja cech trenignowych i testowych\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Konwersja danych do wymaganego formatu\n",
    "x_train = np.array(x_train).astype(float)\n",
    "y_train = np.array(y_train).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcje aktywacji i ich pochodne\n",
    "def relu(x: np.ndarray) -> np.ndarray:\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x: np.ndarray) -> np.ndarray:\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x: np.ndarray) -> np.ndarray:\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja kosztu i jej pochodna\n",
    "def binary_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return -np.mean(y_true * np.log(y_pred + 1e-15) + (1 - y_true) * np.log(1 - y_pred + 1e-15))\n",
    "\n",
    "def binary_cross_entropy_derivative(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "    return (y_pred - y_true) / (y_pred * (1 - y_pred) + 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasa pojedynczej warstwy\n",
    "class SingleLayer:\n",
    "    def __init__(self,\n",
    "                 input_layer_size : int,\n",
    "                 output_layer_size : int,\n",
    "                 activation : Callable[[np.ndarray, np.ndarray], float],\n",
    "                 activation_derivative : Callable[[np.ndarray, np.ndarray], float],\n",
    "                 std_dev : float = 0.01\n",
    "                 )-> None:\n",
    "        self.weights : np.ndarray = np.random.randn(input_layer_size, output_layer_size) * std_dev\n",
    "        self.biases : np.ndarray = np.zeros((1, output_layer_size))\n",
    "        self.activation : Callable[[np.ndarray, np.ndarray], float] = activation\n",
    "        self.activation_derivative : Callable[[np.ndarray, np.ndarray], float] = activation_derivative\n",
    "    \n",
    "    def forward(self, feature_matrix: np.ndarray) -> np.ndarray:\n",
    "        self.z = feature_matrix @ self.weights + self.biases\n",
    "        self.a = self.activation(self.z)\n",
    "        self.cache_x = feature_matrix\n",
    "        return self.a\n",
    "\n",
    "    def backward(self, gradient: np.ndarray) -> np.ndarray:\n",
    "        delta = gradient * self.activation_derivative(self.z)\n",
    "        self.d_weights = self.cache_x.T @ delta\n",
    "        self.d_biases = np.sum(delta, axis=0, keepdims=True)\n",
    "        return delta @ self.weights.T\n",
    "\n",
    "    def update(self, learning_rate: float) -> None:\n",
    "        self.weights -= learning_rate * self.d_weights\n",
    "        self.biases -= learning_rate * self.d_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasa sieci neuronowej\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_dims: list[int], std_dev: float = 0.01) -> None:\n",
    "        self.layers: list[SingleLayer] = []\n",
    "        for i in range(len(layer_dims) - 1):\n",
    "            input_size: int = layer_dims[i]\n",
    "            output_size: int = layer_dims[i + 1]\n",
    "            if i < len(layer_dims) - 2:  # warstwy ukryte\n",
    "                self.layers.append(SingleLayer(input_size, output_size, relu, relu_derivative, std_dev))\n",
    "            else:  # ostatnia warstwa wyjściowa\n",
    "                self.layers.append(SingleLayer(input_size, output_size, sigmoid, sigmoid_derivative, std_dev))\n",
    "\n",
    "    def forward(self, feature_matrix: np.ndarray) -> np.ndarray:\n",
    "        for layer in self.layers:\n",
    "            feature_matrix = layer.forward(feature_matrix)\n",
    "        return feature_matrix\n",
    "\n",
    "    def backward(self, y_pred: np.ndarray, y_true: np.ndarray) -> None:\n",
    "        gradient: np.ndarray = binary_cross_entropy_derivative(y_true, y_pred)\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient = layer.backward(gradient)\n",
    "\n",
    "    def update_weights(self, learning_rate: float) -> None:\n",
    "        for layer in self.layers:\n",
    "            layer.update(learning_rate)\n",
    "\n",
    "    def train(self, feature_matrix: np.ndarray, labels: np.ndarray, epochs: int, learning_rate_param: float) -> None:\n",
    "        global learning_rate\n",
    "        learning_rate = learning_rate_param\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(feature_matrix)\n",
    "            cost = binary_cross_entropy(labels, y_pred)\n",
    "            self.backward(y_pred, labels)\n",
    "            self.update_weights(learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Cost: {cost}\")\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return (self.forward(X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.6931471712791074\n",
      "Epoch 100, Cost: 0.691642024463924\n",
      "Epoch 200, Cost: 0.6916420225034614\n",
      "Epoch 300, Cost: 0.6916420206971673\n",
      "Epoch 400, Cost: 0.6916420187553498\n",
      "Epoch 500, Cost: 0.6916420166666967\n",
      "Epoch 600, Cost: 0.6916420143019294\n",
      "Epoch 700, Cost: 0.6916420115271491\n",
      "Epoch 800, Cost: 0.6916420083325854\n",
      "Epoch 900, Cost: 0.6916420027700538\n",
      "Accuracy: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Przykład użycia modelu\n",
    "if __name__ == \"__main__\":\n",
    "    # Ustawienia modelu\n",
    "    layer_dims = [25, 8, 4, 2, 1]  # Przykładowe wymiary: input -> hidden -> output\n",
    "    learning_rate = 0.01\n",
    "    epochs = 1000\n",
    "\n",
    "    # Tworzenie, trenowanie i testowanie modelu\n",
    "    model = NeuralNetwork(layer_dims)\n",
    "    model.train(x_train, y_train, epochs, learning_rate)\n",
    "\n",
    "    # Sprawdzenie predykcji\n",
    "    predictions = model.predict(x_test)\n",
    "    accuracy = np.mean(predictions == y_test)\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
